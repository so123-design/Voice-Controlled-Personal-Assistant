{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "91fddf86",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# **Voice-Controlled Personal Assistant Using GPT-2**\n",
    "\n",
    "## **Introduction**\n",
    "This project implements a **Voice-Controlled Personal Assistant** named **Samir**, which interacts with the user through voice commands. The assistant can manage tasks, take screenshots, answer questions using a GPT-2 language model, and perform other utility functions such as opening a web browser. This project highlights the integration of speech recognition, text-to-speech conversion, and AI-driven text generation.\n",
    "\n",
    "---\n",
    "\n",
    "## **Project Components**\n",
    "\n",
    "### **1. Key Features**\n",
    "- **Task Management**: Add and display a list of personal tasks.\n",
    "- **Screenshot Capture**: Take and save screenshots with a timestamped filename.\n",
    "- **Web Browsing**: Open a web browser to access the internet.\n",
    "- **Question Answering**: Respond to user queries using the GPT-2 model.\n",
    "- **Speech Interaction**: Utilize speech recognition for input and text-to-speech for output.\n",
    "\n",
    "---\n",
    "\n",
    "### **2. Libraries Used**\n",
    "1. **pyttsx3**: Converts text into speech, allowing the assistant to communicate with the user.\n",
    "2. **SpeechRecognition**: Captures user voice commands via a microphone and converts them into text.\n",
    "3. **webbrowser**: Opens web pages based on voice commands.\n",
    "4. **pyautogui**: Captures screenshots of the current screen.\n",
    "5. **transformers**: Provides access to the GPT-2 model for generating answers to questions.\n",
    "6. **datetime**: Generates timestamps for naming screenshot files.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7a1eda9",
   "metadata": {},
   "source": [
    "## **System Workflow**\n",
    "\n",
    "### **1. Text-to-Speech and local GPT model Initialization**\n",
    "The assistant initializes text-to-speech engine and GPT model with configurable properties like rate (speed) and volume.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "942020c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pyttsx3\n",
    "import speech_recognition as sr\n",
    "import webbrowser\n",
    "import pyautogui\n",
    "from transformers import pipeline\n",
    "import datetime\n",
    "\n",
    "\n",
    "\n",
    "# Initialize text-to-speech engine\n",
    "engine = pyttsx3.init()\n",
    "engine.setProperty('rate', 150)\n",
    "engine.setProperty('volume', 1.0)\n",
    "\n",
    "def speak(text):\n",
    "    \"\"\"Convert text to speech.\"\"\"\n",
    "    engine.say(text)\n",
    "    engine.runAndWait()\n",
    "\n",
    "# Initialize the local GPT model\n",
    "print(\"Loading GPT model... This may take a while.\")\n",
    "gpt_model = pipeline(\"text-generation\", model=\"gpt2\")\n",
    "\n",
    "# Task list\n",
    "tasks = []\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "921eb9a9",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### **2. Speech Recognition**\n",
    "The assistant listens to user voice input through a microphone and converts it into text. Background noise is accounted for to improve accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a29de176",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Recognize speech using microphone\n",
    "def listen():\n",
    "    \"\"\"Listen to voice input and convert it to text.\"\"\"\n",
    "    recognizer = sr.Recognizer()\n",
    "    with sr.Microphone() as source:\n",
    "        print(\"Listening...\")\n",
    "        recognizer.adjust_for_ambient_noise(source)\n",
    "        audio = recognizer.listen(source)\n",
    "    try:\n",
    "        print(\"Recognizing...\")\n",
    "        command = recognizer.recognize_google(audio)\n",
    "        print(f\"You said: {command}\")\n",
    "        return command.lower()\n",
    "    except sr.UnknownValueError:\n",
    "        speak(\"Sorry, I didn't catch that. Could you please repeat?\")\n",
    "        return \"\"\n",
    "    except sr.RequestError:\n",
    "        speak(\"Sorry, I'm having trouble accessing the speech recognition service.\")\n",
    "        return \"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e1f632e",
   "metadata": {},
   "source": [
    "### **3. Question Answering**\n",
    "The project uses the GPT-2 language model to answer user queries. The model generates responses based on the input text.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1391497b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def answer_question(question):\n",
    "    \"\"\"Use GPT model to generate an answer for the given question.\"\"\"\n",
    "    response = gpt_model(question, max_length=50, num_return_sequences=1)[0]['generated_text']\n",
    "    return response"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2d39b2f",
   "metadata": {},
   "source": [
    "### **4. Handling Voice Commands**\n",
    "The assistant processes user commands to perform tasks such as adding tasks, taking screenshots, opening a browser, and answering questions.\n",
    "\n",
    "#### **Key Commands:**\n",
    "- **Add Task**: Adds a task to a task list.\n",
    "- **Show Tasks**: Displays the list of tasks.\n",
    "- **Take Screenshot**: Saves a screenshot with a timestamp.\n",
    "- **Open Browser**: Opens a web browser to Google.\n",
    "- **Answer Questions**: Uses GPT-2 to respond to queries.\n",
    "- **Exit**: Terminates the assistant."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37f9a719",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Main function to handle commands\n",
    "def handle_command(command):\n",
    "    \"\"\"Process voice commands and perform tasks.\"\"\"\n",
    "    if \"add task\" in command:\n",
    "        task = command.replace(\"add task\", \"\").strip()\n",
    "        if task:\n",
    "            tasks.append(task)\n",
    "            speak(f\"Task '{task}' has been added to your list.\")\n",
    "        else:\n",
    "            speak(\"Please specify the task to add.\")\n",
    "\n",
    "    elif \"show tasks\" in command:\n",
    "        if tasks:\n",
    "            speak(\"Here are your tasks:\")\n",
    "            for i, task in enumerate(tasks, start=1):\n",
    "                speak(f\"Task {i}: {task}\")\n",
    "        else:\n",
    "            speak(\"Your task list is empty.\")\n",
    "\n",
    "    elif \"take screenshot\" in command:\n",
    "        screenshot = pyautogui.screenshot()\n",
    "        timestamp = datetime.datetime.now().strftime(\"%Y-%m-%d_%H-%M-%S\")\n",
    "        filename = f\"screenshot_{timestamp}.png\"\n",
    "        screenshot.save(filename)\n",
    "        speak(f\"Screenshot saved as {filename}.\")\n",
    "\n",
    "    elif \"open browser\" in command:\n",
    "        webbrowser.open(\"https://www.google.com\")\n",
    "        speak(\"Browser opened.\")\n",
    "\n",
    "    elif \"what is\" in command or \"who is\" in command or \"tell me about\" in command:\n",
    "        response = answer_question(command)\n",
    "        speak(response)\n",
    "\n",
    "    elif \"exit\" in command or \"quit\" in command:\n",
    "        speak(\"Goodbye! Have a great day.\")\n",
    "        exit()\n",
    "\n",
    "    else:\n",
    "        speak(\"I'm not sure how to help with that.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11d6db6f",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### **5. Main Loop**\n",
    "The assistant continuously listens for commands and executes corresponding functions, creating an interactive experience."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7dae8d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Main loop\n",
    "if __name__ == \"__main__\":\n",
    "    speak(\"Hello! I'm Samir, your personal assistant. How can I help you today?\")\n",
    "    while True:\n",
    "        user_command = listen()\n",
    "        if user_command:\n",
    "            handle_command(user_command)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9e5e7fd",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## **How to Run the Project**\n",
    "\n",
    "### **1. Prerequisites**\n",
    "Install the required libraries:\n",
    "```bash\n",
    "pip install pyttsx3\n",
    "pip install SpeechRecognition\n",
    "pip install transformers\n",
    "pip install pyautogui\n",
    "pip install pyaudio\n",
    "```\n",
    "\n",
    "### **2. Running the Code**\n",
    "Run the Python script to launch the assistant. Speak into the microphone when prompted, and interact with the assistant using natural language.\n",
    "\n",
    "---\n",
    "\n",
    "## **Key Features**\n",
    "\n",
    "| Feature               | Description                                                                 |\n",
    "|-----------------------|-----------------------------------------------------------------------------|\n",
    "| **Task Management**   | Add and display tasks using voice commands.                                |\n",
    "| **Screenshots**       | Capture and save screenshots with a timestamp.                             |\n",
    "| **Web Browsing**      | Open Google using a voice command.                                         |\n",
    "| **Question Answering**| Use GPT-2 to respond to questions with AI-generated text.                  |\n",
    "| **Speech Interaction**| Provides text-to-speech responses for an interactive experience.           |\n",
    "\n",
    "---\n",
    "\n",
    "## **Applications**\n",
    "- **Personal Productivity**: Manage tasks and perform quick actions hands-free.\n",
    "- **Learning**: Use the GPT-2 integration to answer general knowledge questions.\n",
    "- **Utility Tool**: Capture screenshots and browse the web with voice commands.\n",
    "\n",
    "---\n",
    "\n",
    "## **Future Enhancements**\n",
    "- **Enhanced Voice Commands**: Add support for advanced actions like sending emails or setting reminders.\n",
    "- **Improved Question Answering**: Use a larger GPT model for more accurate and context-aware answers.\n",
    "- **Multilingual Support**: Incorporate speech recognition and text-to-speech for multiple languages.\n",
    "- **GUI Integration**: Develop a user-friendly interface for task management and interaction.\n",
    "\n",
    "---\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
